# An√°lise de Algoritmos Paralelos e Seriais
Universidade Federal do Rio Grande do Norte ([UFRN](http://http://www.ufrn.br)), 2020.

#### An√°lise por:
- [Oziel Alves](https://github.com/ozielalves/)

## Sum√°rio

+ [Objetivos](#objetivos)
+ [Depend√™ncias](#depend√™ncias)
  + [G++ Compiler](#g-compiler)
  + [MPI](#mpi---message-passing-interface)
+ [Compila√ß√£o e Execu√ß√£o](#compila√ß√£o-e-execu√ß√£o)
  + [Arquivo com Resultados](#arquivo-com-resultados)
+ [Apresenta√ß√£o dos Algoritmos](#apresenta√ß√£o-dos-algoritmos)
  + [C√°lculo do Pi](#c√°lculo-do-pi---m√©todo-de-monte-carlo)
    + [Serial](#serial)
    + [Paralelo](#paralelo)
+ [Resultados - An√°lise de Efici√™ncia](#resultados---an√°lise-de-efici√™ncia)
  + [Corretude](#corretude)
+ [An√°lise de Speedup](#c√°lculo-do-pi---an√°lise-de-speedup)
  + [Serial e Paralelo - Tempo x Tamanho do Problema](#serial-e-paralelo---tempo-x-tamanho-do-problema)
  + [Paralelo - Tempo x Cores](#paralelo---tempo-x-cores)
+ [Condi√ß√µes de Testes](#condi√ß√µes-de-testes)
  + [Informa√ß√µes sobre a m√°quina utilizada](#informa√ß√µes-sobre-a-m√°quina-utilizada)
  + [Softwares utilizados](#softwares-utilizados)

## Objetivos
Analisar e avaliar o comportamento, eficien√™ncia e speedup dos algoritmos em rela√ß√£o ao seu tempo de execu√ß√£o, tamanho do problema e resultados obtidos. Os cen√°rios ir√£o simular a execu√ß√£o dos algoritmos para 2, 4 e 8 cores, no caso dos algor√≥timos paralelos, com alguns tamanhos de problema definidos empiricamente, sendo o menor tamanho estabelecido no objetivo at√© atingir o tempo m√≠nimo de execu√ß√£o determinado pela refer√™ncia da An√°lise (30 segundos).

## Depend√™ncias
#### G++ Compiler
√â necess√°rio para a compila√ß√£o do programa, visto que ele √© feito em c++.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install g++
```
#### MPI - Message Passing Interface
√â necess√°rio para a compila√ß√£o e execu√ß√£o dos c√≥digos paralelos.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install -y mpi 
```
### Compila√ß√£o e Execu√ß√£o
Instaladas as depend√™ncias, basta executar o shellcript determinado para a devida bateria de execu√ß√µes na raiz do reposit√≥rio:<br>
Note que ser√£o realizados **5 execu√ß√µes** com **4 tamanhos de problema** , em **3 quantidades de cores** (2, 4 e 8).
```bash
# Para o algor√≠timo que calcula o pi de forma serial
./pi_serial_start.sh
```
```bash
# Para o algor√≠timo que calcula o pi de forma paralela
./pi_paralelo_start.sh
```
**Obs.:** Caso seja necess√°rio conceder permiss√£o m√°xima para os scripts, execute `chmod 777 [NOME DO SCRIPT].sh`.
### Arquivo com Resultados 
Ap√≥s o termino das execu√ß√µes do script √© poss√≠vel ter acesso aos arquivos `.txt` na pasta `pi`, os dados coletados foram utilizados para realiza√ß√£o desta an√°lise.

## Apresenta√ß√£o dos Algoritmos

### C√°lculo do Pi - M√©todo de Monte Carlo
O algor√≠timo √© baseado no m√©todo Monte Carlo para estimar o valor de **`ùúã`**. O m√©todo de Monte Carlo depende de amostragem independente e aleat√≥ria repetida, ele funciona bem com sistemas paralelos e distribu√≠dos, pois o trabalho pode ser dividido entre v√°rios processos. Sua ideia principal √© simular um grande n√∫mero de realiza√ß√µes de um evento estat√≠stico. Neste sentido, o uso de multiplos processadores permite a realiza√ß√£o de um n√∫mero fixo de eventos por processador, o que aumenta o n√∫mero total de eventos simulados.<br> 
No c√°lculo de Pi, em espec√≠fico, o algor√≠timo implementado tem como base a gera√ß√£o de diversos pontos cujas coordenadas s√£o n√∫meros aleat√≥rios com fun√ß√£o de desnsidade de probabilildade constante num intervalo indo de 0 a 1. Assim, a probabilidadede que os pontos estejam dentro do quadrado definido pelo produto cartesiano [0,1]x[0,1] √© unit√°ria. Se, de todos os pontos gerados, contarmos aqueles cuja norma euclidiana √© menor ou igual a 1 √© poss√≠vel encontrar a probabilidade de que um ponto esteja dentro do quarto de c√≠rculo centrado na origem de raio 1, que √© proporcional a sua √°rea. Com isso, e sabendo a √°rea de 1/4 de c√≠rculo basta uma manipula√ß√£o alg√©brica para encontrar o valor de pi aproximado. Assim:

```bash
   pi = 4 * (pontos_dentro_do_c√≠rculo)/(pontos_totais)
```

#### Serial
Dado um n√∫mero de pontos a serem definidos, que iremos apelidar como `termos`, a seguinte sub-rotina √© implementada. 

1. √â setado o valor `acertos` = 0.0.

2. `termos` determinar√° a quatidade de pontos `x` e `y` a serem definidos randomicamente com seed fixa = 42, dentro do intervalo de 0.0 a 1.0.

3. Caso `( x * x + y * y )` seja menor que 1.0, `acertos` √© acrescido em 1 unidade.

4. Ao termino do la√ßo, para conclus√£o do m√©todo de Monte Carlo,  √© retornado `acertos` multiplicado por 4 e dividido por `termos`.

A implementa√ß√£o da fun√ß√£o calcPi √© apresentada abaixo:
```bash
double calcPi(int termos)
{
    # Gerador Mersene twist, SEED: 42
    mt19937 mt(42);
    
    # Numero real pseudo-aleatorio
    uniform_real_distribution<double> linear_r(0.f, 1.f);

    int acertos = 0;
    for (int i = 0; i < termos; i++)
    {

        double x = linear_r(mt);
        double y = linear_r(mt);
        
        if (x * x + y * y < 1.0)
        {
            acertos++;
        }
    }
    return (double)(4.0 * acertos / termos);
}
```

#### Paralelo
Ainda referente a pontos a serem definidos como `termos`, a seguinte sub-rotina √© implementada.  

1. O tamanho do problema `termos` √© lido por por linha de comando.

2. √â iniciada a comunica√ß√£o paralela.

3. `termos_local` recebe `termos` dividido pela quantidade de processos.

4.  `termos_local` √© passado como parametro pra o c√°culo parcial dos acertos, usando a fun√ß√£o j√° apresentada `calcPi`, e armazenado em cada processo como `acertos_parc`.

5. Ao termino da execu√ß√£o de cada processo , `acertos_parc` √© somado a `acertos`.

6. Quando todos os processos s√£o finalizados, √© fechada a comunical√ßao MPI e ent√£o impresso o valor do resultado final multiplicado por 4 e dividido por `termos`.

**Obs.:** Vale salientar que, por escolha particular, a multiplica√ß√£o e divis√£o realizada no n√∫mero de acertos foi realizada apenas na impress√£o do resultado, diferente do que acontece naturalmente da fun√ß√£o `calcPi`, no c√≥digo paralelo √© retornado apenas a quantidade de acertos.

A implementa√ß√£o do Paralelismo √© apresentado abaixo:
```bash
int main(int argc, char **argv)
{
    struct timeval start, stop;
    gettimeofday(&start, 0);

    int my_rank;
    int p;
    int termos = atoll(argv[1]);
    int termos_local;
    int inicial_local;
    double acertos_parc;
    double acertos;

    MPI_Init(&argc, &argv);

    // Rank do meu processo
    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);

    // Descobre quantos processos estao em uso
    MPI_Comm_size(MPI_COMM_WORLD, &p);

    // Divisao interna
    termos_local = termos / p;

    // Bloqueia o processo at√© todos chegarem nesse ponto
    MPI_Barrier(MPI_COMM_WORLD);

    acertos_parc = calcPi(termos_local);

    // Soma o numero de acertos por cada processo
    MPI_Reduce(&acertos_parc, &acertos, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
    if (my_rank == 0)
    {
        gettimeofday(&stop, 0);

        FILE *fp;
        char outputFilename[] = "./pi/tempo_mpi_pi.txt";

        fp = fopen(outputFilename, "a");
        if (fp == NULL)
        {
            fprintf(stderr, "Nao foi possivel abrir o arquivo %s!\n", outputFilename);
            exit(1);
        }

        fprintf(fp, "\tTempo: %1.2e \tResultado: %f\n",
                ((double)(stop.tv_usec - start.tv_usec) / 1000000 + (double)(stop.tv_sec - start.tv_sec)),
                (double)4 * acertos / termos);

        fclose(fp);
    }
    else
    { /* Nothing */ }

    MPI_Finalize();
}
```

## Resultados - An√°lise de Efici√™ncia
Para esta an√°lise, ser√£o realizados **5 execu√ß√µes** com os tamanhos de problema 374.500.000, 550.000.000, 900.000.000 e 1.500.000.000 - definidos empiricamente de modo a atingir os limites m√≠nimos determinados pela refer√™ncia - em **3 quantidades de cores** (2, 4 e 8). Se espera que o comportamento de ambos os algor√≠timos quanto realiza√ß√£o da aproxima√ß√£o do Pi correta e coerente de acordo com um tamanho de problema, a descri√ß√£o completa da m√°quina de testes pode ser encontrada no t√≥pico [Condi√ß√µes de Testes](#condi√ß√µes-de-testes).

### Corretude

Para validar a corretude dos Algor√≠timos implementados foi realizado um teste utilizando **4550000** como tamanho de problema para os dois c√≥digos:

![Alt Corretude - Pi Paralelo e Pi Serial](./data/pi_graphs/pi_terminal_print.PNG)

Como √© poss√≠vel perceber, ambos os c√≥digos conseguem aproximar de maneira correta o valor de pi, dado o n√∫mero de pontos solicitados.<br><br>
**Obs.:** Vale salientar que para este modelo de amostragem quanto maior o n√∫mero de pontos a serem definidos mais preciso ser√° o valor de pi retornado.

## C√°lculo do Pi - An√°lise de Speedup

### Serial e Paralelo - Tempo x Tamanho do Problema

![Alt Serial e Paralelo - Tempo x Tamanho do Problema](./data/pi_graphs/serial_paralelo_tempo_por_tamanho_do_problema.PNG)

Atrav√©s do gr√°fico comparativo √© poss√≠vel observar uma diferen√ßa significantemente positiva no tempo de execu√ß√£o para os tamanhos de problemas no c√≥digo serial para tempo de execu√ß√£o dos mesmos problemas no c√≥digo paralelo, o menor problema √© executado em pouco mais de 40 segundo no c√≥digo serial, j√° no c√≥digo paralelo, o mesmo problema √© executado em pouco menos de 20 segundos em seu maior uso de cores. No entanto, note que a diferen√ßa em termos de tempo de execu√ß√£o para o c√≥digo paralelo utilizando 4 e 8 cores √© praticamente inexistente devido aos limites da m√°quina de teste.

### Paralelo - Tempo x Cores

![Alt Paralelo - Tempo x Cores](./data/pi_graphs/paralelo_tempo_por_cores.PNG)

No gr√°fico de compara√ß√£o dos tempos de execu√ß√£o por tamanho de problema, a rela√ß√£o speedup pode ser melhor visualizada de acordo com o n√∫mero de cores, Note que o tempo de execu√ß√£o para o problema de maior tamanho cai cerca de 80% quando executado no c√≥digo paralelo ultilizando 2 cores.

### Speedup por N√∫mero de cores
Ao coletar os dados das diferentes an√°lises, o tempo m√©dio de execu√ß√£o do c√≥digo serial para cada tamanho de problema foi dividido pelo mesmo valor relativo a cada problema executado no c√≥digo paralelo, obtendo assim o speedup para cada tamanho de problema. √â poss√≠vel ver na tabela abaixo o speedup m√©dio geral por n√∫mero de cores utilizados na execu√ß√£o do c√≥digo paralelo.
| N√∫mero de Cores | 2 | 4 | 8 |
| --- | --- | ---| --- |
|**Speedup M√©dio**|1.80|2.47|2.44| 

## Considera√ß√µes Finais

Devido aos limites da m√°quina de testes n√£o foi poss√≠vel estender o n√∫mero de cores utilizados, ficou muito bastante explicito 4 cores como o limite de cores a serem utilizados pelo dispositivo de maneira a trazer um speedup relevante. Apesar disto, atrav√©s desta an√°lise foi poss√≠vel perceber que a paraleliza√ß√£o de c√≥digos seriais, ainda que simples, tr√°s resultados bastante promissores no que diz respeito a efici√™ncia e velocidade, se faz pertinente tamb√©m visualizar o aumento do speedup de maneira ainda mais consider√°vel quando o tamanho do problema √© aumentado. 

## Condi√ß√µes de Testes
### Informa√ß√µes sobre a m√°quina utilizada
+ **Dell Inspiron 14-inc 7460**

+ **Processador**: Intel Core i7 7500U (at√© 3.5 GHz) Dual Core Cache 4M. (FSB)4 GT/s OPI (
Integra HyperThreading para trabalhar com at√© 4 threads de uma vez)

+ **N√∫mero de Cores/Threads**: 2/4

+ **Mem√≥ria**: 8 GB tipo DDR4 ‚Äì 2133MHz

+ **Sistema**: Ubuntu 20.04.1 LTS

### Softwares utilizados
```bash
~$: g++ --version
g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

```bash
~$: python3 --version
Python 3.6.4
```

```bash
~$: pip3 --version
pip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6)
```
