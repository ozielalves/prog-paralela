# An√°lise de Algoritmos Paralelos e Seriais
Universidade Federal do Rio Grande do Norte ([UFRN](http://http://www.ufrn.br)), 2020.

#### An√°lise por:
- [Oziel Alves](https://github.com/ozielalves/)

## Sum√°rio

+ [Objetivos](#objetivos)
+ [Instru√ß√µes de Uso](#instru√ß√µes-de-uso)
  + [Depend√™ncias](#depend√™ncias)
    + [G++ Compiler](#g-compiler)
    + [MPI](#mpi---message-passing-interface)
  + [Compila√ß√£o e Execu√ß√£o](#compila√ß√£o-e-execu√ß√£o)
+ [Apresenta√ß√£o dos Algoritmos](#apresenta√ß√£o-dos-algoritmos)
  + [C√°lculo do Pi](#c√°lculo-do-pi)
    + [Serial](#serial)
    + [Paralelo](#paralelo)
    + [An√°lise de Speedup](#an√°lise-de-speedup)
      + [Serial e Paralelo - Tempo x Tamanho do Problema](#serial-e-paralelo---tempo-x-tamanho-do-problema)
      + [Paralelo - Tempo x Cores](#paralelo---tempo-x-cores)
     + [An√°lise de Efici√™ncia](#an√°lise-de-efici√™ncia)
  + [C√°lculo da Integral - Regrado do Trap√©zio](#c√°lculo-da-integral---regra-do-trap√©zio)
    + [Serial](#serial)
    + [Paralelo](#paralelo)
    + [An√°lise de Speedup](#an√°lise-de-speedup)
      + [Serial e Paralelo - Tempo x Tamanho do Problema](#serial-e-paralelo---tempo-x-tamanho-do-problema)
      + [Paralelo - Tempo x Cores](#paralelo---tempo-x-cores)
     + [An√°lise de Efici√™ncia](#an√°lise-de-efici√™ncia)
+ [Condi√ß√µes de Testes](#condi√ß√µes-de-testes)
  + [Informa√ß√µes sobre a m√°quina utilizada](#informa√ß√µes-sobre-a-m√°quina-utilizada)
  + [Informa√ß√µes sobre os parametros utilizados](#informa√ß√µes-sobre-os-parametros-utilizados)
  + [Softwares utilizados](#softwares-utilizados)

## Objetivos
Analisar e avaliar o comportamento, eficien√™ncia e speedup dos algoritmos em rela√ß√£o ao seu tempo de execu√ß√£o, tamanho do problema e resultados obtidos. Os cen√°rios ir√£o simular a execu√ß√£o dos algoritmos para 2, 4 e 8 cores, no caso dos algor√≥timos paralelos, com alguns tamanhos de problema definidos empiricamente, sendo o menor tamanho estabelecido no objetivo at√© atingir o tempo m√≠nimo de execu√ß√£o determinado pela refer√™ncia da An√°lise (30 segundos).

## Instru√ß√µes de uso
#### G++ Compiler
√â necess√°rio para a compila√ß√£o do programa, visto que ele √© feito em c++.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install g++
```
#### MPI - Message Passing Interface
√â necess√°rio para a compila√ß√£o e execu√ß√£o dos c√≥digos paralelos.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install -y mpi 
```
### Compila√ß√£o e Execu√ß√£o
Instaladas as depen√™ncias, basta executar o shellcript determinado para a devida bateria de execu√ß√µes na raiz do reposit√≥rio:<br>
Note que ser√£o realizados **5 execu√ß√µes** com **4 tamanhos de problema** espec√≠ficos para cada problema, em **3 quantidades de cores** (2, 4 e 8).
```bash
# Para o algor√≠timo que calcula o pi de forma serial
./pi_serial_start.sh
```
```bash
# Para o algor√≠timo que calcula o pi de forma paralela
./pi_paralelo_start.sh
```
```bash
# Para o algor√≠timo que calcula a integral de forma serial
./trap_serial_start.sh
```
```bash
# Para o algor√≠timo que calcula a integral de forma paralela
./trap_paralelo_start.sh
```
Obs.: Caso seja necess√°rio conceder permiss√£o m√°xima para os scripts, execute `chmod 777 [NOME DO SCRIPT].sh`.
### Resultados
Ap√≥s o termino das execu√ß√µes do script √© poss√≠vel ter acesso aos arquivos `.txt` na pasta `pi` ou `trapezio`, de acordo com o script selecionado, os dados coletados foram utilizados para realiza√ß√£o desta an√°lise.

## Apresenta√ß√£o dos Algoritmos

### C√°lculo do Pi
O algor√≠timo demonstra o m√©todo Monte Carlo para estimar o valor de **ùúã**. O m√©todo de Monte Carlo depende de amostragem independente e aleat√≥ria repetida. Esses m√©todos funcionam bem com sistemas paralelos e distribu√≠dos, pois o trabalho pode ser dividido entre v√°rios processos.

#### Serial
Dado um n√∫mero de pontos a serem definidos, que iremos apelidar como `termos`, a seguinte sub-rotina √© implementada. 

1. √â setado o valor `acertos` = 0.0.

2. `termos` determinar√° a quatidade de pontos `x` e `y` a serem definidos randomicamente com seed fixa = 42, dentro do intervalo de 0.0 a 1.0.

3. Caso `( x * x + y * y )` seja menor que 1.0, `acertos` √© acrescido em 1 unidade.

4. Ao termino do la√ßo, para conclus√£o do m√©todo de Monte Carlo,  √© retornado `acertos` multiplicado por 4 e dividido por `termos`.

A implementa√ß√£o da fun√ß√£o calcPi √© apresentada abaixo:
```bash
double calcPi(int termos)
{
    # Gerador Mersene twist, SEED: 42
    mt19937 mt(42);
    
    # Numero real pseudo-aleatorio
    uniform_real_distribution<double> linear_r(0.f, 1.f);

    int acertos = 0;
    for (int i = 0; i < termos; i++)
    {

        double x = linear_r(mt);
        double y = linear_r(mt);
        
        if (x * x + y * y < 1.0)
        {
            acertos++;
        }
    }
    return (double)(4.0 * acertos / termos);
}
```

#### Paralelo
Ainda referente a pontos a serem definidos como `termos`, a seguinte sub-rotina √© implementada.  

1. O tamanho do problema `termos` √© lido por por linha de comando.

2. √â iniciada a comunica√ß√£o paralela.

3. `termos_local` recebe `termos` dividido pela quantidade de processos.

4.  `termos_local` √© passado como parametro pra o c√°culo parcial dos acertos, usando a fun√ß√£o j√° apresentada `calcPi`, e armazenado em cada processo como `acertos_parc`.

5. Ao termino da execu√ß√£o de cada processo , `acertos_parc` √© somado a `acertos`.

6. Quando todos os processos s√£o finalizados, √© fechada a comunical√ßao MPI e ent√£o impresso o valor do resultado final multiplicado por 4 e dividido por `termos`.

**Obs.:** Vale salientar que por escolha particular a multiplica√ß√£o e divis√£o realizada no n√∫mero de acertos foi realizada apenas na impress√£o do resultado, diferente do que acontece naturalmente da fun√ß√£o `calcPi`, no c√≥digo paralelo √© retornado apenas a quantidade de acertos.

A implementa√ß√£o do Paralelismo √© apresentado abaixo:
```bash
int main(int argc, char **argv)
{
    struct timeval start, stop;
    gettimeofday(&start, 0);

    int my_rank;
    int p;
    int termos = atoll(argv[1]);
    int termos_local;
    int inicial_local;
    double acertos_parc;
    double acertos;

    MPI_Init(&argc, &argv);

    # Rank do meu processo
    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);

    # Descobre quantos processos estao em uso
    MPI_Comm_size(MPI_COMM_WORLD, &p);

    # Divisao interna
    termos_local = termos / p;

    acertos_parc = calcPi(termos_local);

    # Soma o numero de acertos por cada processo
    MPI_Reduce(&acertos_parc, &acertos, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
    if (my_rank == 0)
    {

        gettimeofday(&stop, 0);

        FILE *fp;
        char outputFilename[] = "./pi/tempo_mpi_pi.txt";

        fp = fopen(outputFilename, "a");
        if (fp == NULL)
        {
            fprintf(stderr, "Nao foi possivel abrir o arquivo %s!\n", outputFilename);
            exit(1);
        }

        fprintf(fp, "\tTempo: %1.2e \tResultado: %f\n",
                ((double)(stop.tv_usec - start.tv_usec) / 1000000 + (double)(stop.tv_sec - start.tv_sec)),
                (double)4 * acertos / termos);

        fclose(fp);
    }
    else
    { 
      /* Nothing */
    }

    MPI_Finalize();
}
```

##### An√°lise de Speedup
![Alt Serial e Paralelo - Tempo x Tamanho do Problema](./data/pi_graphs/serial_paralelo_tempo_por_tamanho_do_problema.PNG)
![Alt Paralelo - Tempo x Cores](./data/pi_graphs/paralelo_tempo_por_cores.PNG)
##### An√°lise de Efici√™ncia
Vale salientar que para este modelo de amostragem quanto maior o n√∫mero de pontos a serem definidos mais preciso ser√° o valor de pi retornado.
![Alt Tamanho x Itera√ß√µes](./pi/lonely/1-Sequential%20Search_14.png)

### C√°lculo da Integral usando a Regra do Trap√©zio
```bash
/*
 * Peter S. Pacheco, An Introduction to Parallel Programming,
 * Morgan Kaufmann Publishers, 2011
 * IPP:   Section 3.4.2 (pp. 104 and ff.)
 * Timing and command line argument added by Hannah Sonsalla, 
 * Macalester College, 2017
 *
 * mpi_trap.c
 *
 * ... Use MPI to implement a parallel version of the trapezoidal
 *     rule.  Uses collective communications to distribute the
 *     input data and compute the global sum.
 *
 * Input:    Number of trapezoids
 * Output:   Estimate of the integral from a to b of f(x)
 *           using the trapezoidal rule and n trapezoids.
 *
 * Usage:    mpirun -np <number of processes> ./mpi_trap < number of trapezoids>
 *
 * Algorithm:
 *    1.  Each process calculates "its" interval of
 *        integration.
 *    2.  Each process estimates the integral of f(x)
 *        over its interval using the trapezoidal rule.
 *    3a. Each process != 0 sends its integral to 0.
 *    3b. Process 0 sums the calculations received from
 *        the individual processes and prints the result.
 *
 * Note:  f(x) is all hardwired to x*x.
 *
 */
```
Tamb√©m conhecida como busca logaritmica, √© um algoritmo de busca baseado na t√©cnica *divide and conquer* e dependente de uma ordena√ß√£o, que melhora not√°velmente sua performance, visto que a cada itera√ß√£o, √© descartado metade do conjunto.
#### Iterativa
Dado um conjunto $A$ de $n$ elementos ordenados e um alvo $T$, √© seguida a sub-rotina para encontrar o elemento:

1. √â setado $L = 0$ e $R = n - 1$.
2. Se $L < R$ , a busca termina sem sucesso.
3. √â setado a posi√ß√£o do meio ($m$) do elemento para  $\left \lfloor \frac{L + R}{2}\right \rfloor$.
4. Se $A_m < T$, ser√° setado $L = m + 1$ e retorna ao passo 2.
5. Se $A_m > T$, ser√° setado $R = m - 1$ e retorna ao passo 2.
6. Se $A_m = T$, a busca √© finalizada retornando $m$.



Pelo fato da busca bin√°ria utilizar-se do m√©todo *divide and conquer*, acaba se tornando uma fun√ß√£o logaritma que, em seu melhor caso, o elemento procurado estar√° exatamente em $\frac{n}{2}$ , j√° em seu pior caso, ir√° ter $\mathcal{O} \log_2 n$ compara√ß√µes.

##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/2-Iterative%20Binary_14.png)
###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/2-Iterative%20Binary_13.png)

#### Recursiva

Apesar de possuir a mesma complexidade de tempo da Bin√°ria Iterativa, sua vers√£o recursiva pode variar drasticamente em termos de mem√≥ria consumida durante a execu√ß√£o (ir√° depender tanto do compilador quanto das otimiza√ß√µes feitas pelo programador).

##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/3-Recursive%20Binary_14.png)
###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/3-Recursive%20Binary_13.png)

√â de fato um m√©todo de busca imensamente mais eficiente que o algoritmo de busca linear. Por√©m uma de suas desvantagens aparece quando o vetor n√£o √© ordenado (seja por impossibilidade, fluxo de entrada constante, n√∫meros repetidos ...) ou quando o vetor implementado n√£o suporta *random acess*, como por exemplo, listas encadeadas.

### Busca Tern√°ria
Busca Tern√°ria √© uma t√©cnica em ci√™ncia da computa√ß√£o para encontrar o m√≠nimo ou o m√°ximo de uma fun√ß√£o unimodal. Uma busca tern√°ria determina se o m√≠nimo ou o m√°ximo podem ou n√£o estar no primeiro ter√ßo do dom√≠nio ou se ele pode ou n√£o estar no √∫ltimo ter√ßo do dom√≠nio e, em seguida, repete o passo para o terceiro restante.
#### Iterativa
Seja $f(x)$ uma fun√ß√£o unimodal num intervalo $[ l ; r ]$. Pega-se dois pontos $m1$ e $m2$ no segmento: $l < m1 < m2 < r$ 

Depois, segue-se tr√™s passos:

1. Se $f(m1) < f(m2)$: Ent√£o o elemento buscado n√£o pode ser localizado no lado esquerdo $[ l ; m1 ]$. Ent√£o olha-se apenas no intervalo $[ m1 ; r ]$
2. Se $f(m1) > f(m2)$, que a situa√ß√£o √© semelhante √† anterior, at√© a simetria. Agora, o elemento buscado n√£o pode estar no lado direito $[ m2 ; r ]$, ent√£o olha-se no segmento $[ l ; m2 ]$
3. Se $f(m1) = f(m2)$, a busca deve ser realizada em $[ m1 ; m2 ]$, mas este caso pode ser atribu√≠do a qualquer um dos dois anteriores (para simplificar o c√≥digo).

Recomenda√ß√µes para $m1$ e $m2$: 

‚Äã	$m1 = \frac{l + (r-l)}{3}$ 

‚Äã	$m2 = \frac{r - (r- l) }{3}$


Devido a divis√£o recurssiva do vetor por 3, a fun√ß√£o, em seu pior caso, assume comportamento logar√≠timico, o que gera uma complexidade de $\mathcal{O} (log_3 n)$.

##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/5-Iterative%20Ternary_14.png)
###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/5-Iterative%20Ternary_13.png)
#### Recursiva
##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/6-Recursive%20Ternary_14.png)
###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/6-Recursive%20Ternary_13.png)
√â uma fun√ß√£o pouco usada, visto que a busca bin√°ria faz basicamente o mesmo trabalho s√≥ que com uma compara√ß√£o a menos em cada itera√ß√£o, causando uma complexidade de $2 \log_3(n)$, contra $\log_2(n)$ da busca bin√°ria.

### Jump Search
<!--Breve explica√ß√£o-->
Como a Binary Search, Jump Search, ou Block Search √© um algoritmo de pesquisa para arrays ordenados. A id√©ia b√°sica √© verificar menos elementos (do que a busca linear) saltando por etapas fixas ou ignorando alguns elementos no lugar de pesquisar todos os elementos.
<!--Pseudo-C√≥digo-->
Dada um vetor ordenado $L$, seu comprimento , queremos achar o elemento $S$.

Sendo $L_{min(a, b) - 1}$ o menor elemento entre $a$ e $b$:

1. Iremos setar $a = 0$ e $b = 0$

1. Enquanto que $L_{min((b, n) -1)}$ < $S$:  Iremos setar $a = b$ e $b = b + ‚åä‚àön‚åã$
2. Se $a ‚â• n$, o programa termina e √© retornado `null`.
3. Enquanto que $L_a$ < $S$: Iremos incrementar $a$ em 1 unidade.
4. Se $a = min (b, n)$, o programa termina e √© retornado `null`.
5. Se $L_a$ = $S$, ser√° retornado $a$.
6. Se n√£o: √© retornado `null`.

<!--Complexidade-->
Devido a compara√ß√£o dos blocos formados,ambas as etapas do algoritmo observam, no m√°ximo, ‚àön itens, o que leva o algoritmo a apresentar em seu pior caso complexidade $\mathcal{O}\sqrt[]n$.

##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/4-Jump%20Search_14.png)

###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/4-Jump%20Search_13.png)
<!--Opni√£o-->

√â de fato uma alternativa melhor que a busca sequencial, por√©m pior do que a busca bin√°ria. Pode ser um algoritmo √∫til caso empregado em casos espec√≠ficos bem planejados, tais como um vetor que as chances do elemento buscado estar em uma das posi√ß√µes multiplas de $\sqrt{n}$ seja alta.

### Busca Fibonacci
<!--Breve explica√ß√£o-->
Fibonacci Search √© uma t√©cnica baseada em compara√ß√£o, em um array ordenado, que empregando a filosofia _divide and conquer_, usa n√∫meros da sequ6encia Fibonacci para pesquisar um elemento em um determinado vetor.

<!--Pseudo-C√≥digo-->
1. Encontra o menor n√∫mero de Fibonacci maior ou igual ao valor passado para a busca (`value`). 
2. Deixe que este n√∫mero seja $fib_m$
3. Deixe que os dois n√∫meros de Fibonacci que precedem sejam $fib_{m-1}$  e $fib_{m-2}$.
4. Enquanto o vetor possui elementos a serem inspecionados:
  1. Compara `value` com o √∫ltimo elemento da gama coberta por $fib_{m-2}$
  2. Se `value` corresponder, retorna endere√ßo.
  3. Se $fib_m$ < `value`, reduz $fib_{m-2}$, $fib_{m-1}$ e $fib_m$ em dois n√∫meros de fibonacci, indicando a elimina√ß√£o de cerca de dois ter√ßos do vetor restante
  4. Se $fib_m$ for menor que value, reduz $fib{m-2}$, $fib_{m-1}$ e $fib_m$ em tr√™s n√∫meros de fibonacci, redefina o deslocamento para o endere√ßo. Juntos, estes passos indicam a elimina√ß√£o de cerca de um ter√ßo do vetor restante.

Devido a elimina√ß√£o de ranges, em seu pior caso a busca Fibonacci acaba se tornando uma fun√ß√£o logar√≠timica de complexidade $\mathcal{O}\log n$.

##### Gr√°ficos exclusivos
###### Tamanho x Itera√ß√µes
![Alt Tamanho x Itera√ß√µes](./pi/lonely/7-Fibonacci%20Search_14.png)
###### Tamanho x Tempo m√©dio
![Alt Tamanho x Tempo m√©dio](./pi/lonely/7-Fibonacci%20Search_13.png)
<!--Opni√£o-->
No geral, a busca fibonacci leva a aproximadamente 4% mais compara√ß√µes que a busca bin√°ria. Por√©m, sua real vantagem est√° no fato que s√≥ necessita de adi√ß√µes e subtra√ß√µes (se implementada corretamente), o que torna o trabalho da CPU muito menos danoso do que em divis√µes (como na bin√°ria).

Quando os elementos est√£o em uma mem√≥ria n√£o totalmente uniforme (i.e. quando o tempo de acesso a determinadas partes da mem√≥ria pode variar), ela tamb√©m pode levar uma pequena vantagem em rela√ß√£o a busca bin√°ria pois reduz pouca coisa a quantidade de acessos √† mem√≥ria. 

## Compara√ß√µes Gerais
### Recursivos x Iterativos
#### Busca Bin√°ria

A busca bin√°ria em suas duas vers√µes apresenta complexidade de tempo semelhante, visto o gr√°fico abaixo. A √∫nica diferen√ßa entre as duas √© que uma ir√° (provavelmente) consumir mais mem√≥ria devido a recursividade.

![Alt Iterativo x Recursivo (Por tempo)](./pi/versus/2-Iterative%20Binary_3-Recursive%20Binary_13.png)
#### Busca Tern√°ria

Mesma aspecto observado na bin√°ria, √∫nica diferen√ßa √© que a vers√£o recursiva (provavelmente) consumir√° mais mem√≥ria devido a sua recursividade.

![Alt Iterativo x Recursivo (Por tempo)](./pi/versus/5-Iterative%20Ternary_6-Recursive%20Ternary_13.png)

### Recursivos x Busca Fibonacci
#### Tamanho x Itera√ß√µes

[Fibonacci x Recursive Binary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/3-Recursive%20Binary_7-Fibonacci%20Search_14.png)

[Fibonacci x Recursive Ternary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/6-Recursive%20Ternary_7-Fibonacci%20Search_14.png)

#### Tamanho x Tempo

[Fibonacci x Recursive Binary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/3-Recursive%20Binary_7-Fibonacci%20Search_13.png)

[Fibonacci x Recursive Ternary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/6-Recursive%20Ternary_7-Fibonacci%20Search_13.png)

### Recursivos x Jump Search
#### Tamanho x Itera√ß√µes
[Jump Search x Recursive Binary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/3-Recursive%20Binary_4-Jump%20Search_14.png)

[Jump Search x Recursive Ternary](./pi/versus/4-Jump%20Search_6-Recursive%20Ternary_14.png)

#### Tamanho x Tempo
[Jump Search x Recursive Binary](https://github.com/ozielalves/Analise_empirica/blob/master/pi/versus/3-Recursive%20Binary_4-Jump%20Search_13.png)

[Jump Search x Recursive Ternary](./pi/versus/4-Jump%20Search_6-Recursive%20Ternary_13.png)

## Condi√ß√µes de Testes
### Informa√ß√µes sobre a maquina utilizada
+ **Dell Inspiron 14' 7460** (13-inch, 2017)

+ **Processador** Intel Core i7 7500U (at√© 3.5 GHz) Cache 4M. (FSB)4 GT/s OPI

+ **Mem√≥ria** 8 GB tipo DDR4 ‚Äì 2133MHz

+ **Sistema** Ubuntu 20.04.1 LTS

### Informa√ß√µes sobre os parametros utilizados
Todos as informa√ß√µes interpretadas neste documento foram obtidas utilizando o seguinte comando::
```bash
# Ir√° compilar e executar o arquivo bin√°rio, em seguida o script gerador de gr√°ficos (src/gen_plot.py)
make run
```
### Softwares utilizados
```bash
~$: g++ --version
g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

```bash
~$: python3 --version
Python 3.6.4
```

```bash
~$: pip3 --version
pip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6)
```
