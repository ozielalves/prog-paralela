# An√°lise de Algoritmos Paralelos e Seriais
Universidade Federal do Rio Grande do Norte ([UFRN](http://http://www.ufrn.br)), 2020.

#### An√°lise por:
- [Oziel Alves](https://github.com/ozielalves/)

## Sum√°rio

+ [Objetivos](#objetivos)
+ [Depend√™ncias](#depend√™ncias)
  + [G++ Compiler](#g-compiler)
  + [MPI](#mpi---message-passing-interface)
+ [Compila√ß√£o e Execu√ß√£o](#compila√ß√£o-e-execu√ß√£o)
  + [Arquivo com Resultados](#arquivo-com-resultados)
+ [Apresenta√ß√£o dos Algoritmos](#apresenta√ß√£o-dos-algoritmos)
  + [C√°lculo do Pi](#c√°lculo-do-pi---m√©todo-de-monte-carlo)
    + [Serial](#serial)
    + [Paralelo](#paralelo)
+ [Resultados - An√°lise de Efici√™ncia](#resultados---an√°lise-de-efici√™ncia)
  + [Corretude](#corretude)
+ [An√°lise de Speedup](#c√°lculo-do-pi---an√°lise-de-speedup)
  + [Serial e Paralelo - Tempo x Tamanho do Problema](#serial-e-paralelo---tempo-x-tamanho-do-problema)
  + [Paralelo - Tempo x Cores](#paralelo---tempo-x-cores)
+ [Condi√ß√µes de Testes](#condi√ß√µes-de-testes)
  + [Informa√ß√µes sobre a m√°quina utilizada](#informa√ß√µes-sobre-a-m√°quina-utilizada)
  + [Softwares utilizados](#softwares-utilizados)

## Objetivos
Analisar e avaliar o comportamento, efici√™ncia e speedup dos algoritmos em rela√ß√£o ao seu tempo de execu√ß√£o, tamanho do problema analisado e resultados obtidos. Os cen√°rios ir√£o simular a execu√ß√£o dos algoritmos para 2, 4 e 8 cores, no caso dos algoritmos paralelos, com alguns tamanhos de problema definidos empiricamente, sendo o menor tamanho estabelecido com o objetivo de atingir o tempo m√≠nimo de execu√ß√£o determinado pela refer√™ncia da An√°lise (30 segundos).

## Depend√™ncias
#### G++ Compiler
√â necess√°rio para a compila√ß√£o dos programam, visto que s√£o feitos em c++.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install g++
```
#### MPI - Message Passing Interface
√â necess√°rio para a compila√ß√£o e execu√ß√£o dos c√≥digos paralelos.
```bash
# Instala√ß√£o no Ubuntu 20.04 LTS:
sudo apt-get install -y mpi 
```
### Compila√ß√£o e Execu√ß√£o
Instaladas as depend√™ncias, basta executar o shellcript determinado para a devida bateria de execu√ß√µes na raiz do reposit√≥rio:<br>
Ser√£o realizadas **5 execu√ß√µes** com **4 tamanhos de problema** , em **3 quantidades de cores** (2, 4 e 8).
```bash
# Para o algor√≠timo que calcula o pi de forma serial
./pi_serial_start.sh
```
```bash
# Para o algor√≠timo que calcula o pi de forma paralela
./pi_paralelo_start.sh
```
**Obs.:** Caso seja necess√°rio conceder permiss√£o m√°xima para os scripts, execute `chmod 777 [NOME DO SCRIPT].sh`.
### Arquivo com Resultados 
Ap√≥s o termino das execu√ß√µes do script √© poss√≠vel ter acesso aos arquivos `.txt` na pasta `pi`. Os dados coletados foram utilizados para realiza√ß√£o desta an√°lise.

## Apresenta√ß√£o dos Algoritmos

### C√°lculo do Pi - M√©todo de Monte Carlo
O algoritmo √© baseado no m√©todo de Monte Carlo para estimar o valor de **`ùúã`**. Eleo depende de amostragem independente e aleat√≥ria repetida, e funciona bem com sistemas paralelos e distribu√≠dos, pois o trabalho pode ser dividido entre v√°rios processos. Sua ideia principal √© simular um grande n√∫mero de realiza√ß√µes de um evento estat√≠stico. Neste sentido, o uso de multiplos processadores permite a realiza√ß√£o de um n√∫mero fixo de eventos por processador, o que aumenta o n√∫mero total de eventos simulados.<br> 
No c√°lculo de Pi, em espec√≠fico, o algoritmo implementado tem como base a gera√ß√£o de diversos pontos, cujas coordenadas s√£o n√∫meros aleat√≥rios com fun√ß√£o de desnsidade de probabilildade constante em um intervalo indo de 0 a 1. Assim, a probabilidadede que os pontos estejam dentro do quadrado definido pelo produto cartesiano [0,1]x[0,1] √© unit√°ria. Se, de todos os pontos gerados, contarmos aqueles cuja norma euclidiana √© menor ou igual a 1, √© poss√≠vel encontrar a probabilidade de que um ponto esteja dentro do quarto de c√≠rculo centrado na origem e de raio 1, que √© proporcional a sua √°rea. Com isso, e sabendo a √°rea de 1/4 de c√≠rculo, basta uma manipula√ß√£o alg√©brica para encontrar o valor de pi aproximado. Assim:

```bash
   pi = 4 * (pontos_dentro_do_c√≠rculo)/(pontos_totais)
```

#### Serial
Dado um n√∫mero de pontos a serem definidos, que chamaremos de `termos`, a seguinte sub-rotina √© implementada: 

1. √â setado o valor `acertos` = 0.0.

2. `termos` determinar√° a quatidade de pontos `x` e `y` a serem definidos randomicamente com seed fixa = 42, dentro do intervalo de 0.0 a 1.0.

3. Caso `( x * x + y * y )` seja menor que 1.0, `acertos` √© acrescido em 1 unidade.

4. Ao termino do la√ßo, para conclus√£o do m√©todo de Monte Carlo,  √© retornado `acertos` multiplicado por 4 e dividido por `termos`.

A implementa√ß√£o da fun√ß√£o calcPi √© apresentada abaixo:
```bash
double calcPi(int termos)
{
    # Gerador Mersene twist, SEED: 42
    mt19937 mt(42);
    
    # Numero real pseudo-aleatorio
    uniform_real_distribution<double> linear_r(0.f, 1.f);

    int acertos = 0;
    for (int i = 0; i < termos; i++)
    {

        double x = linear_r(mt);
        double y = linear_r(mt);
        
        if (x * x + y * y < 1.0)
        {
            acertos++;
        }
    }
    return (double)(4.0 * acertos / termos);
}
```

#### Paralelo
Ainda referente chamando o numero total de pontos a serem definidos como `termos`, a seguinte sub-rotina √© implementada:  

1. O tamanho do problema, `termos` √© lido por por linha de comando.

2. √â iniciada a comunica√ß√£o paralela.

3. `termos_local` recebe `termos` dividido pela quantidade de processos.

4.  `termos_local` √© passado como parametro para o c√°culo parcial dos acertos, usando a fun√ß√£o j√° apresentada, `calcPi`, e armazenado em cada processo como `acertos_parc`.

5. Ao termino da execu√ß√£o de cada processo , `acertos_parc` √© somado a `acertos`.

6. Quando todos os processos finalizam a contagem de acertos, todos os acertos parciais s√£o somados a `acertos`, ent√£o, √© fechada a comunica√ß√£o MPI e ent√£o impresso o valor do resultado final multiplicado por 4 e dividido por `termos`.

**Obs.:** Vale salientar que, por escolha particular, a multiplica√ß√£o e divis√£o realizada no n√∫mero de acertos foi realizada apenas na impress√£o do resultado. Diferentemente do que acontece naturalmente da fun√ß√£o `calcPi`, no c√≥digo paralelo √© retornado apenas a quantidade de acertos.

A implementa√ß√£o do Paralelismo √© apresentada abaixo:
```bash
int main(int argc, char **argv)
{
    struct timeval start, stop;
    gettimeofday(&start, 0);

    int my_rank;
    int p;
    int termos = atoll(argv[1]);
    int termos_local;
    int inicial_local;
    double acertos_parc;
    double acertos;

    MPI_Init(&argc, &argv);

    # Rank do meu processo
    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);

    # Descobre quantos processos estao em uso
    MPI_Comm_size(MPI_COMM_WORLD, &p);

    # Divisao interna
    termos_local = termos / p;

    # Bloqueia o processo at√© todos chegarem nesse ponto
    MPI_Barrier(MPI_COMM_WORLD);

    acertos_parc = calcPi(termos_local);

    # Soma o numero de acertos por cada processo
    MPI_Reduce(&acertos_parc, &acertos, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
    if (my_rank == 0)
    {
        gettimeofday(&stop, 0);

        FILE *fp;
        char outputFilename[] = "./pi/tempo_mpi_pi.txt";

        fp = fopen(outputFilename, "a");
        if (fp == NULL)
        {
            fprintf(stderr, "Nao foi possivel abrir o arquivo %s!\n", outputFilename);
            exit(1);
        }

        fprintf(fp, "\tTempo: %1.2e \tResultado: %f\n",
                ((double)(stop.tv_usec - start.tv_usec) / 1000000 + (double)(stop.tv_sec - start.tv_sec)),
                (double)4 * acertos / termos);

        fclose(fp);
    }
    else
    { /* Nothing */ }

    MPI_Finalize();
}
```

## Resultados - An√°lise de Efici√™ncia
Para esta an√°lise, ser√£o realizadas **5 execu√ß√µes** com tamanhos de problema 374.500.000, 550.000.000, 900.000.000 e 1.500.000.000 - definidos empiricamente de modo a atingir os limites m√≠nimos determinados pela refer√™ncia - em **3 quantidades de cores** (2, 4 e 8). Se espera que o comportamento de ambos os algoritmos quanto a aproxima√ß√£o do Pi seja parecido para um mesmo tamanho de problema quando se altera apenas o n√∫mero de cores, sendo o tempo de execu√ß√£o o √∫nico fator vari√°vel. Uma descri√ß√£o completa da m√°quina de testes pode ser encontrada no t√≥pico [Condi√ß√µes de Testes](#condi√ß√µes-de-testes).

### Corretude

Para validar a corretude dos algoritmos implementados foi realizado um teste utilizando **4550000** como tamanho de problema para os dois c√≥digos:

![Alt Corretude - Pi Paralelo e Pi Serial](./data/pi_graphs/pi_terminal_print.PNG)

Como √© poss√≠vel perceber, ambos os c√≥digos conseguem aproximar de maneira correta o valor de pi, dado o n√∫mero de pontos solicitados.<br><br>
**Obs.:** Vale salientar que para este modelo de amostragem quanto maior o n√∫mero de pontos a serem definidos mais preciso ser√° o valor de pi retornado.

## C√°lculo do Pi - An√°lise de Speedup

### Serial e Paralelo - Tempo x Tamanho do Problema

![Alt Serial e Paralelo - Tempo x Tamanho do Problema](./data/pi_graphs/serial_paralelo_tempo_por_tamanho_do_problema.PNG)

Atrav√©s do gr√°fico comparativo, √© poss√≠vel observar que o c√≥digo paralelo √© mais eficiente que o c√≥digo serial pois a reta relativa a este √∫ltimo apresenta um coefiente angular maior do que as relativas ao primeiro, o que indica que ao se aumentar o temanho de problema no c√≥digo serial o aumento em tempo de execu√ß√£o √© proporcionalmente maior que o que seria observado no c√≥digo paralelo. Vale salientar que as curvas referentes a 4 e 8 cores s√£o praticamente id√™nticas, isso ocorre devido aos limites da m√°quina de teste, fen√¥meno que ser√° mais bem explicado no item [Considera√ß√µes Finais](#consider√ß√µes-finais).

### Paralelo - Tempo x Cores

![Alt Paralelo - Tempo x Cores](./data/pi_graphs/paralelo_tempo_por_cores.PNG)

A partir do gr√°fico apresentado, √© clara a influ√™ncia do n√∫mero de cores no tempo de execu√ß√£o. Por exemplo, o tempo de execu√ß√£o para o problema de maior tamanho cai cerca de 45% ao se passar do c√≥digo serial para o c√≥digo paralelo ultilizando 2 cores. Novamente, verifica-se que o desempenho para 4 e 8 cores √© id√™ntico.

### Speedup por N√∫mero de cores
√â poss√≠vel definir o speedup, quando da utiliza√ß√£o de n cores, como sendo o tempo de execu√ß√£o no c√≥digo serial divido pelo tempo m√©dio de execu√ß√£o para n cores. Dessa forma, o speedup representa um aumento m√©dio de velocidade na resolu√ß√£o dos problemas. A tabela abaixo apresenta o speedup m√©dio por n√∫mero de cores utilizados na execu√ß√£o do c√≥digo paralelo.
| N√∫mero de Cores | 2 | 4 | 8 |
| --- | --- | ---| --- |
|**Speedup M√©dio**|1.80|2.47|2.44| 

## Considera√ß√µes Finais

Devido aos limites da m√°quina de testes, o n√∫mero de cores pass√≠veis de utiliza√ß√£o √© restrito. Das an√°lises apresentadas, fica explicito que 4 cores √© o limite do dispositivo de maneira a ter um speedup relevante, apesar do processador integrar HyperThreading. foi poss√≠vel estender o n√∫mero de cores utilizados, ficou muito bastante explicito 4 cores como o limite de cores a serem utilizados pelo dispositivo de maneira a trazer um speedup relevante. Apesar disto, atrav√©s desta an√°lise foi poss√≠vel perceber que a paraleliza√ß√£o de c√≥digos seriais, ainda que simples, traz resultados bastante promissores no que diz respeito a efici√™ncia e velocidade. As an√°lises tamb√©m permitiram constatar que o speedup √© ainda mais pronunciado para tamanhos maiores de problema.

## Condi√ß√µes de Testes
### Informa√ß√µes sobre a m√°quina utilizada
+ **Dell Inspiron 14-inc 7460**

+ **Processador**: Intel Core i7 7500U (at√© 3.5 GHz) Dual Core Cache 4M. (FSB)4 GT/s OPI (
Integra HyperThreading para trabalhar com at√© 4 threads de uma vez)

+ **N√∫mero de Cores/Threads**: 2/4

+ **Mem√≥ria**: 8 GB tipo DDR4 ‚Äì 2133MHz

+ **Sistema**: Ubuntu 20.04.1 LTS

### Softwares utilizados
```bash
~$: g++ --version
g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

```bash
~$: python3 --version
Python 3.6.4
```

```bash
~$: pip3 --version
pip 9.0.1 from /usr/local/lib/python3.6/site-packages (python 3.6)
```
